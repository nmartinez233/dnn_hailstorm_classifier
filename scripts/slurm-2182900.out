distributed.nanny - INFO -         Start Nanny at: 'tcp://10.70.130.46:41387'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.70.130.46:45799'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.70.130.46:40707'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.70.130.46:39148'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.70.130.46:41134'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.70.130.46:45481'
distributed.diskutils - INFO - Found stale lock file and directory '/lcrc/group/earthscience/nmartinez/dnn_hailstorm_classifier/scripts/dask-worker-space/worker-6_i0pisv', purging
distributed.worker - INFO -       Start worker at:   tcp://10.70.130.46:39042
distributed.worker - INFO -          Listening to:   tcp://10.70.130.46:39042
distributed.worker - INFO -          dashboard at:         10.70.130.46:40266
distributed.worker - INFO - Waiting to connect to:   tcp://140.221.70.8:37165
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          6
distributed.worker - INFO -                Memory:                  19.87 GiB
distributed.worker - INFO -       Local Directory: /lcrc/group/earthscience/nmartinez/dnn_hailstorm_classifier/scripts/dask-worker-space/worker-1vcp6byh
distributed.worker - INFO -       Start worker at:   tcp://10.70.130.46:39859
distributed.worker - INFO -       Start worker at:   tcp://10.70.130.46:42525
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://10.70.130.46:39859
distributed.worker - INFO -          Listening to:   tcp://10.70.130.46:42525
distributed.worker - INFO -          dashboard at:         10.70.130.46:41023
distributed.worker - INFO -          dashboard at:         10.70.130.46:41613
distributed.worker - INFO - Waiting to connect to:   tcp://140.221.70.8:37165
distributed.worker - INFO - Waiting to connect to:   tcp://140.221.70.8:37165
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          6
distributed.worker - INFO -               Threads:                          6
distributed.worker - INFO -                Memory:                  19.87 GiB
distributed.worker - INFO -                Memory:                  19.87 GiB
distributed.worker - INFO -       Local Directory: /lcrc/group/earthscience/nmartinez/dnn_hailstorm_classifier/scripts/dask-worker-space/worker-6e6_79mp
distributed.worker - INFO -       Local Directory: /lcrc/group/earthscience/nmartinez/dnn_hailstorm_classifier/scripts/dask-worker-space/worker-pwl_mv0r
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.70.130.46:45808
distributed.worker - INFO -       Start worker at:   tcp://10.70.130.46:40350
distributed.worker - INFO -       Start worker at:   tcp://10.70.130.46:35498
distributed.worker - INFO -          Listening to:   tcp://10.70.130.46:45808
distributed.worker - INFO -          Listening to:   tcp://10.70.130.46:40350
distributed.worker - INFO -          Listening to:   tcp://10.70.130.46:35498
distributed.worker - INFO -          dashboard at:         10.70.130.46:34273
distributed.worker - INFO -          dashboard at:         10.70.130.46:41728
distributed.worker - INFO -          dashboard at:         10.70.130.46:33650
distributed.worker - INFO - Waiting to connect to:   tcp://140.221.70.8:37165
distributed.worker - INFO - Waiting to connect to:   tcp://140.221.70.8:37165
distributed.worker - INFO - Waiting to connect to:   tcp://140.221.70.8:37165
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          6
distributed.worker - INFO -               Threads:                          6
distributed.worker - INFO -                Memory:                  19.87 GiB
distributed.worker - INFO -               Threads:                          6
distributed.worker - INFO -                Memory:                  19.87 GiB
distributed.worker - INFO -       Local Directory: /lcrc/group/earthscience/nmartinez/dnn_hailstorm_classifier/scripts/dask-worker-space/worker-5emxwxdv
distributed.worker - INFO -       Local Directory: /lcrc/group/earthscience/nmartinez/dnn_hailstorm_classifier/scripts/dask-worker-space/worker-rfz3f538
distributed.worker - INFO -                Memory:                  19.87 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /lcrc/group/earthscience/nmartinez/dnn_hailstorm_classifier/scripts/dask-worker-space/worker-fvg14gin
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://140.221.70.8:37165
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://140.221.70.8:37165
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://140.221.70.8:37165
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://140.221.70.8:37165
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://140.221.70.8:37165
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://140.221.70.8:37165
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Event loop was unresponsive in Worker for 5.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.45s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.46s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 5.47s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 2.33s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 2.53s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 2.26s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 2.27s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 2.28s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 1.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.worker - WARNING - Compute Failed
Function:  make_LRP
args:      ('../clustering/KTLX_4/KLOT_trained/cluster2/20190830-144724.png')
kwargs:    {}
Exception: RuntimeError("Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size")

distributed.worker - WARNING - Compute Failed
Function:  make_LRP
args:      ('../clustering/KTLX_4/KLOT_trained/cluster2/20191107-112156.png')
kwargs:    {}
Exception: RuntimeError("Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size")

distributed.worker - WARNING - Compute Failed
Function:  make_LRP
args:      ('../clustering/KTLX_4/KLOT_trained/cluster2/20200525-222148.png')
kwargs:    {}
Exception: RuntimeError("Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size")

distributed.worker - WARNING - Compute Failed
Function:  make_LRP
args:      ('../clustering/KTLX_4/KLOT_trained/cluster2/20200117-003548.png')
kwargs:    {}
Exception: RuntimeError("Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size")

distributed.worker - WARNING - Compute Failed
Function:  make_LRP
args:      ('../clustering/KTLX_4/KLOT_trained/cluster2/20200318-022316.png')
kwargs:    {}
Exception: RuntimeError("Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size")

distributed.worker - WARNING - Compute Failed
Function:  make_LRP
args:      ('../clustering/KTLX_4/KLOT_trained/cluster2/20200210-233054.png')
kwargs:    {}
Exception: RuntimeError("Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size")

distributed.worker - WARNING - Compute Failed
Function:  make_LRP
args:      ('../clustering/KTLX_4/KLOT_trained/cluster2/20191128-134858.png')
kwargs:    {}
Exception: RuntimeError("Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size")

distributed.worker - WARNING - Compute Failed
Function:  make_LRP
args:      ('../clustering/KTLX_4/KLOT_trained/cluster2/20200330-195320.png')
kwargs:    {}
Exception: RuntimeError("Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size")

distributed.worker - WARNING - Compute Failed
Function:  make_LRP
args:      ('../clustering/KTLX_4/KLOT_trained/cluster2/20190830-160305.png')
kwargs:    {}
Exception: RuntimeError("Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size")

distributed.worker - WARNING - Compute Failed
Function:  make_LRP
args:      ('../clustering/KTLX_4/KLOT_trained/cluster2/20190830-142338.png')
kwargs:    {}
Exception: RuntimeError("Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size")

distributed.worker - WARNING - Compute Failed
Function:  make_LRP
args:      ('../clustering/KTLX_4/KLOT_trained/cluster2/20200525-232245.png')
kwargs:    {}
Exception: RuntimeError("Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size")

distributed.worker - WARNING - Compute Failed
Function:  make_LRP
args:      ('../clustering/KTLX_4/KLOT_trained/cluster2/20200330-194005.png')
kwargs:    {}
Exception: RuntimeError("Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size")

distributed.worker - WARNING - Compute Failed
Function:  make_LRP
args:      ('../clustering/KTLX_4/KLOT_trained/cluster2/20191128-133135.png')
kwargs:    {}
Exception: RuntimeError("Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size")

distributed.worker - WARNING - Compute Failed
Function:  make_LRP
args:      ('../clustering/KTLX_4/KLOT_trained/cluster2/20200524-064437.png')
kwargs:    {}
Exception: RuntimeError("Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size")

distributed.worker - WARNING - Compute Failed
Function:  make_LRP
args:      ('../clustering/KTLX_4/KLOT_trained/cluster2/20200128-173034.png')
kwargs:    {}
Exception: RuntimeError("Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size")

distributed.worker - WARNING - Compute Failed
Function:  make_LRP
args:      ('../clustering/KTLX_4/KLOT_trained/cluster2/20200805-110746.png')
kwargs:    {}
Exception: RuntimeError("Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size")

distributed.worker - WARNING - Compute Failed
Function:  make_LRP
args:      ('../clustering/KTLX_4/KLOT_trained/cluster2/20200526-011716.png')
kwargs:    {}
Exception: RuntimeError("Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size")

distributed.worker - WARNING - Compute Failed
Function:  make_LRP
args:      ('../clustering/KTLX_4/KLOT_trained/cluster2/20200122-065314.png')
kwargs:    {}
Exception: RuntimeError("Calculated padded input size per channel: (4 x 4). Kernel size: (7 x 7). Kernel size can't be greater than actual input size")

slurmstepd: error: *** JOB 2182900 ON bdw-0528 CANCELLED AT 2021-07-22T21:12:58 ***
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://10.70.130.46:41387'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.70.130.46:45799'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.70.130.46:40707'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.70.130.46:39148'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.70.130.46:41134'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.70.130.46:45481'
distributed.nanny - INFO - Worker process 10549 was killed by unknown signal
distributed.nanny - INFO - Worker process 10541 was killed by unknown signal
distributed.nanny - INFO - Worker process 10537 was killed by unknown signal
