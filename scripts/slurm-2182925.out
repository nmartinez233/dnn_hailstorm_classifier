distributed.nanny - INFO -         Start Nanny at: 'tcp://10.70.130.46:41006'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.70.130.46:45741'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.70.130.46:38373'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.70.130.46:39081'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.70.130.46:38271'
distributed.nanny - INFO -         Start Nanny at: 'tcp://10.70.130.46:44873'
distributed.diskutils - INFO - Found stale lock file and directory '/lcrc/group/earthscience/nmartinez/dnn_hailstorm_classifier/scripts/dask-worker-space/worker-f9dxjf4k', purging
distributed.diskutils - INFO - Found stale lock file and directory '/lcrc/group/earthscience/nmartinez/dnn_hailstorm_classifier/scripts/dask-worker-space/worker-oc5pmxz0', purging
distributed.diskutils - INFO - Found stale lock file and directory '/lcrc/group/earthscience/nmartinez/dnn_hailstorm_classifier/scripts/dask-worker-space/worker-qbcy291l', purging
distributed.diskutils - INFO - Found stale lock file and directory '/lcrc/group/earthscience/nmartinez/dnn_hailstorm_classifier/scripts/dask-worker-space/worker-9v0jkwqm', purging
distributed.diskutils - INFO - Found stale lock file and directory '/lcrc/group/earthscience/nmartinez/dnn_hailstorm_classifier/scripts/dask-worker-space/worker-dc2l0bdm', purging
distributed.worker - INFO -       Start worker at:   tcp://10.70.130.46:35801
distributed.worker - INFO -          Listening to:   tcp://10.70.130.46:35801
distributed.worker - INFO -          dashboard at:         10.70.130.46:44850
distributed.worker - INFO - Waiting to connect to:   tcp://140.221.70.8:41091
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          6
distributed.worker - INFO -                Memory:                  19.87 GiB
distributed.worker - INFO -       Local Directory: /lcrc/group/earthscience/nmartinez/dnn_hailstorm_classifier/scripts/dask-worker-space/worker-asura8nr
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Start worker at:   tcp://10.70.130.46:42922
distributed.worker - INFO -          Listening to:   tcp://10.70.130.46:42922
distributed.worker - INFO -          dashboard at:         10.70.130.46:46048
distributed.worker - INFO - Waiting to connect to:   tcp://140.221.70.8:41091
distributed.worker - INFO -       Start worker at:   tcp://10.70.130.46:44080
distributed.worker - INFO -       Start worker at:   tcp://10.70.130.46:41597
distributed.worker - INFO -       Start worker at:   tcp://10.70.130.46:36252
distributed.worker - INFO -       Start worker at:   tcp://10.70.130.46:34719
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -          Listening to:   tcp://10.70.130.46:44080
distributed.worker - INFO -          Listening to:   tcp://10.70.130.46:41597
distributed.worker - INFO -          Listening to:   tcp://10.70.130.46:36252
distributed.worker - INFO -          Listening to:   tcp://10.70.130.46:34719
distributed.worker - INFO -          dashboard at:         10.70.130.46:34879
distributed.worker - INFO -          dashboard at:         10.70.130.46:39136
distributed.worker - INFO -          dashboard at:         10.70.130.46:45324
distributed.worker - INFO -               Threads:                          6
distributed.worker - INFO -          dashboard at:         10.70.130.46:33753
distributed.worker - INFO - Waiting to connect to:   tcp://140.221.70.8:41091
distributed.worker - INFO - Waiting to connect to:   tcp://140.221.70.8:41091
distributed.worker - INFO - Waiting to connect to:   tcp://140.221.70.8:41091
distributed.worker - INFO -                Memory:                  19.87 GiB
distributed.worker - INFO - Waiting to connect to:   tcp://140.221.70.8:41091
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /lcrc/group/earthscience/nmartinez/dnn_hailstorm_classifier/scripts/dask-worker-space/worker-8qw0jcx7
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          6
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -               Threads:                          6
distributed.worker - INFO -               Threads:                          6
distributed.worker - INFO -                Memory:                  19.87 GiB
distributed.worker - INFO -                Memory:                  19.87 GiB
distributed.worker - INFO -               Threads:                          6
distributed.worker - INFO -                Memory:                  19.87 GiB
distributed.worker - INFO -       Local Directory: /lcrc/group/earthscience/nmartinez/dnn_hailstorm_classifier/scripts/dask-worker-space/worker-ugrrw736
distributed.worker - INFO -       Local Directory: /lcrc/group/earthscience/nmartinez/dnn_hailstorm_classifier/scripts/dask-worker-space/worker-g0odvjvl
distributed.worker - INFO -       Local Directory: /lcrc/group/earthscience/nmartinez/dnn_hailstorm_classifier/scripts/dask-worker-space/worker-takg1kqw
distributed.worker - INFO -                Memory:                  19.87 GiB
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -       Local Directory: /lcrc/group/earthscience/nmartinez/dnn_hailstorm_classifier/scripts/dask-worker-space/worker-p45rg39t
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO - -------------------------------------------------
distributed.worker - INFO -         Registered to:   tcp://140.221.70.8:41091
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://140.221.70.8:41091
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://140.221.70.8:41091
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://140.221.70.8:41091
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://140.221.70.8:41091
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.worker - INFO -         Registered to:   tcp://140.221.70.8:41091
distributed.worker - INFO - -------------------------------------------------
distributed.core - INFO - Starting established connection
distributed.core - INFO - Event loop was unresponsive in Worker for 1.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 1.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 1.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 1.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 1.12s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
distributed.core - INFO - Event loop was unresponsive in Worker for 1.13s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.
lrp.py:21: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).
  plt.figure(figsize=(sx,sy))
distributed.utils_perf - INFO - full garbage collection released 216.92 MiB from 815 reference cycles (threshold: 9.54 MiB)
slurmstepd: error: *** JOB 2182925 ON bdw-0528 CANCELLED AT 2021-07-22T21:30:22 ***
distributed.dask_worker - INFO - Exiting on signal 15
distributed.nanny - INFO - Closing Nanny at 'tcp://10.70.130.46:41006'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.70.130.46:45741'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.70.130.46:38373'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.70.130.46:39081'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.70.130.46:38271'
distributed.nanny - INFO - Closing Nanny at 'tcp://10.70.130.46:44873'
distributed.nanny - INFO - Worker process 16478 was killed by unknown signal
